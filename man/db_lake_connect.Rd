% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/db_connect.R
\name{db_lake_connect}
\alias{db_lake_connect}
\title{Connect to DuckDB + attach a DuckLake catalog}
\usage{
db_lake_connect(
  duckdb_db = ":memory:",
  catalog = "cso",
  catalog_type = c("duckdb", "sqlite", "postgres"),
  metadata_path = "metadata.ducklake",
  data_path = "//CSO-NAS/DataLake",
  snapshot_version = NULL,
  snapshot_time = NULL,
  threads = NULL,
  memory_limit = NULL,
  load_extensions = NULL
)
}
\arguments{
\item{duckdb_db}{DuckDB database file path. Use ":memory:" for in-memory.}

\item{catalog}{DuckLake catalog name inside DuckDB (e.g. "cso")}

\item{catalog_type}{Type of catalog database backend. One of:
\itemize{
\item "duckdb" (default): Single-client local use. Metadata stored in .ducklake file.
\item "sqlite": Multi-client local use. Metadata stored in .sqlite file.
Supports multiple readers + single writer with automatic retry.
Recommended for most CSO use cases with shared network drives.
\item "postgres": Multi-user lakehouse. Metadata stored in PostgreSQL database.
Requires PostgreSQL 12+ and connection string in metadata_path.
}}

\item{metadata_path}{Path or connection string for DuckLake metadata:
\itemize{
\item For "duckdb": file path (e.g. "metadata.ducklake")
\item For "sqlite": file path (e.g. "//CSO-NAS/DataLake/catalog.sqlite")
\item For "postgres": connection string (e.g. "dbname=ducklake_catalog host=localhost")
}}

\item{data_path}{Root storage path where DuckLake writes Parquet data files}

\item{snapshot_version}{Optional integer snapshot version to attach at}

\item{snapshot_time}{Optional timestamp string to attach at (e.g. "2025-05-26 00:00:00")}

\item{threads}{Number of DuckDB threads (NULL leaves default)}

\item{memory_limit}{e.g. "4GB" (NULL leaves default)}

\item{load_extensions}{character vector of extensions to install/load, e.g. c("httpfs")}
}
\value{
DuckDB connection object
}
\description{
Connect to DuckDB + attach a DuckLake catalog
}
\examples{
\dontrun{
# DuckDB catalog (single user, simplest setup)
db_lake_connect(
  metadata_path = "metadata.ducklake",
  data_path = "//CSO-NAS/DataLake"
)

# SQLite catalog (multiple local users - RECOMMENDED for shared drives)
db_lake_connect(
  catalog_type = "sqlite",
  metadata_path = "//CSO-NAS/DataLake/catalog.sqlite",
  data_path = "//CSO-NAS/DataLake/data"
)

# PostgreSQL catalog (multi-user lakehouse, remote clients)
db_lake_connect(
  catalog_type = "postgres",
  metadata_path = "dbname=ducklake_catalog host=db.cso.ie user=analyst",
  data_path = "//CSO-NAS/DataLake/data"
)

# Time travel - connect to a specific snapshot
db_lake_connect(
  catalog_type = "sqlite",
  metadata_path = "catalog.sqlite",
  data_path = "//CSO-NAS/DataLake/data",
  snapshot_version = 5
)
}
}
